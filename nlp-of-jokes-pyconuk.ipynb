{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Analysing the Edinburgh Fringe Festival Jokes\n",
    "\n",
    "**This is a notebook that I used at pyconuk 2015 to check whether the jokes of [The Lightning talk guy](http://www.lightningtalkman.com/) are funny**. It is based on [this blog post](http://vknight.org/unpeudemath/code/2015/06/14/natural-language-and-predicting-funny/) and the series of [BBC articles that list the ranking of jokes at the edinburgh fringe festival](http://www.bbc.co.uk/news/uk-scotland-edinburgh-east-fife-34039927).\n",
    "\n",
    "The basic idea is:\n",
    "\n",
    "![](http://vknight.org/unpeudemath/assets/images/description_of_ratio_learning_for_nlp_jokes.svg)\n",
    "\n",
    "Here are the libraries we are going to need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas  # To handle our data nicely\n",
    "import nltk  # For all the clever stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Loading and tidying the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "df = pandas.read_csv('jokes.csv', quotechar='\"', skipinitialspace=True) #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Author</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Raw_joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 2015</td>\n",
       "      <td>    Darren Walsh</td>\n",
       "      <td> 1</td>\n",
       "      <td> I just deleted all the German names off my pho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 2015</td>\n",
       "      <td> Stewart Francis</td>\n",
       "      <td> 2</td>\n",
       "      <td> Kim Kardashian is saddled with a huge arse ......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 2015</td>\n",
       "      <td>       Adam Hess</td>\n",
       "      <td> 3</td>\n",
       "      <td>             Surely every car is a people carrier?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 2015</td>\n",
       "      <td>    Masai Graham</td>\n",
       "      <td> 4</td>\n",
       "      <td> What's the difference between a 'hippo' and a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 2015</td>\n",
       "      <td>      Dave Green</td>\n",
       "      <td> 5</td>\n",
       "      <td> If I could take just one thing to a desert isl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year           Author  Rank  \\\n",
       "0  2015     Darren Walsh     1   \n",
       "1  2015  Stewart Francis     2   \n",
       "2  2015        Adam Hess     3   \n",
       "3  2015     Masai Graham     4   \n",
       "4  2015       Dave Green     5   \n",
       "\n",
       "                                            Raw_joke  \n",
       "0  I just deleted all the German names off my pho...  \n",
       "1  Kim Kardashian is saddled with a huge arse ......  \n",
       "2              Surely every car is a people carrier?  \n",
       "3  What's the difference between a 'hippo' and a ...  \n",
       "4  If I could take just one thing to a desert isl...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Author</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Raw_joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td> 2009</td>\n",
       "      <td>        Adam Hills</td>\n",
       "      <td>  6</td>\n",
       "      <td> Going to Starbucks for coffee is like going to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td> 2009</td>\n",
       "      <td> Marcus Brigstocke</td>\n",
       "      <td>  7</td>\n",
       "      <td> To the people who've got iPhones: you just bou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td> 2009</td>\n",
       "      <td>      Rhod Gilbert</td>\n",
       "      <td>  8</td>\n",
       "      <td> A spa hotel? It's like a normal hotel, only in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td> 2009</td>\n",
       "      <td>    Dan Antopolski</td>\n",
       "      <td>  9</td>\n",
       "      <td> I've been reading the news about there being a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td> 2009</td>\n",
       "      <td>     Simon Brodkin</td>\n",
       "      <td> 10</td>\n",
       "      <td> I started so many fights at my school - I had ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year             Author  Rank  \\\n",
       "65  2009         Adam Hills     6   \n",
       "66  2009  Marcus Brigstocke     7   \n",
       "67  2009       Rhod Gilbert     8   \n",
       "68  2009     Dan Antopolski     9   \n",
       "69  2009      Simon Brodkin    10   \n",
       "\n",
       "                                             Raw_joke  \n",
       "65  Going to Starbucks for coffee is like going to...  \n",
       "66  To the people who've got iPhones: you just bou...  \n",
       "67  A spa hotel? It's like a normal hotel, only in...  \n",
       "68  I've been reading the news about there being a...  \n",
       "69  I started so many fights at my school - I had ...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting rid of the common word and tokenising the jokes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nltk.download()  # Only do this once: needed to download the `stopwords` corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commonwords = [e.upper() for e in set(nltk.corpus.stopwords.words('english'))] # <- Need to download the corpus: import nltk; nltk.download()\n",
    "commonwords.extend(['M', 'VE'])\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')  #Â To be able to strip out unwanted things in strings\n",
    "string_to_list = lambda x: [el.upper() for el in tokenizer.tokenize(x) if el.upper() not in commonwords]\n",
    "df['Joke'] = df['Raw_joke'].apply(string_to_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Author</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Raw_joke</th>\n",
       "      <th>Joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 2015</td>\n",
       "      <td>    Darren Walsh</td>\n",
       "      <td> 1</td>\n",
       "      <td> I just deleted all the German names off my pho...</td>\n",
       "      <td>       [DELETED, GERMAN, NAMES, PHONE, HANS, FREE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 2015</td>\n",
       "      <td> Stewart Francis</td>\n",
       "      <td> 2</td>\n",
       "      <td> Kim Kardashian is saddled with a huge arse ......</td>\n",
       "      <td> [KIM, KARDASHIAN, SADDLED, HUGE, ARSE, ENOUGH,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 2015</td>\n",
       "      <td>       Adam Hess</td>\n",
       "      <td> 3</td>\n",
       "      <td>             Surely every car is a people carrier?</td>\n",
       "      <td>             [SURELY, EVERY, CAR, PEOPLE, CARRIER]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 2015</td>\n",
       "      <td>    Masai Graham</td>\n",
       "      <td> 4</td>\n",
       "      <td> What's the difference between a 'hippo' and a ...</td>\n",
       "      <td> [DIFFERENCE, HIPPO, ZIPPO, ONE, REALLY, HEAVY,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 2015</td>\n",
       "      <td>      Dave Green</td>\n",
       "      <td> 5</td>\n",
       "      <td> If I could take just one thing to a desert isl...</td>\n",
       "      <td> [COULD, TAKE, ONE, THING, DESERT, ISLAND, PROB...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year           Author  Rank  \\\n",
       "0  2015     Darren Walsh     1   \n",
       "1  2015  Stewart Francis     2   \n",
       "2  2015        Adam Hess     3   \n",
       "3  2015     Masai Graham     4   \n",
       "4  2015       Dave Green     5   \n",
       "\n",
       "                                            Raw_joke  \\\n",
       "0  I just deleted all the German names off my pho...   \n",
       "1  Kim Kardashian is saddled with a huge arse ......   \n",
       "2              Surely every car is a people carrier?   \n",
       "3  What's the difference between a 'hippo' and a ...   \n",
       "4  If I could take just one thing to a desert isl...   \n",
       "\n",
       "                                                Joke  \n",
       "0        [DELETED, GERMAN, NAMES, PHONE, HANS, FREE]  \n",
       "1  [KIM, KARDASHIAN, SADDLED, HUGE, ARSE, ENOUGH,...  \n",
       "2              [SURELY, EVERY, CAR, PEOPLE, CARRIER]  \n",
       "3  [DIFFERENCE, HIPPO, ZIPPO, ONE, REALLY, HEAVY,...  \n",
       "4  [COULD, TAKE, ONE, THING, DESERT, ISLAND, PROB...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our classifier\n",
    "\n",
    "**From here on in we use the jokes up until 2013 as the training set.**\n",
    "\n",
    "We start by getting the entire set of words in all the jokes from the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DELETED',\n",
       " 'GERMAN',\n",
       " 'NAMES',\n",
       " 'PHONE',\n",
       " 'HANS',\n",
       " 'FREE',\n",
       " 'KIM',\n",
       " 'KARDASHIAN',\n",
       " 'SADDLED',\n",
       " 'HUGE']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Year'] = df['Year'].apply(int)\n",
    "\n",
    "def get_all_words(dataframe):\n",
    "    \"\"\"\n",
    "    A function that gets all the words from the Joke column in a given dataframe\n",
    "    \"\"\"\n",
    "    all_words = []\n",
    "    for jk in dataframe['Joke']:\n",
    "        all_words.extend(jk)\n",
    "    return all_words\n",
    "\n",
    "all_words = get_all_words(df)  # Getting the whole database\n",
    "all_words[:10]  # The first ten words in our training data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a function to extract features from a given joke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features(joke, all_words):\n",
    "    words = set(joke)\n",
    "    features = {}\n",
    "    for word in words:\n",
    "        features['contains(%s)' % word] = (word in all_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Author</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Raw_joke</th>\n",
       "      <th>Joke</th>\n",
       "      <th>Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 2015</td>\n",
       "      <td>    Darren Walsh</td>\n",
       "      <td> 1</td>\n",
       "      <td> I just deleted all the German names off my pho...</td>\n",
       "      <td>       [DELETED, GERMAN, NAMES, PHONE, HANS, FREE]</td>\n",
       "      <td> {u'contains(DELETED)': True, u'contains(PHONE)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 2015</td>\n",
       "      <td> Stewart Francis</td>\n",
       "      <td> 2</td>\n",
       "      <td> Kim Kardashian is saddled with a huge arse ......</td>\n",
       "      <td> [KIM, KARDASHIAN, SADDLED, HUGE, ARSE, ENOUGH,...</td>\n",
       "      <td> {u'contains(ENOUGH)': True, u'contains(KANYE)'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 2015</td>\n",
       "      <td>       Adam Hess</td>\n",
       "      <td> 3</td>\n",
       "      <td>             Surely every car is a people carrier?</td>\n",
       "      <td>             [SURELY, EVERY, CAR, PEOPLE, CARRIER]</td>\n",
       "      <td> {u'contains(EVERY)': True, u'contains(PEOPLE)'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 2015</td>\n",
       "      <td>    Masai Graham</td>\n",
       "      <td> 4</td>\n",
       "      <td> What's the difference between a 'hippo' and a ...</td>\n",
       "      <td> [DIFFERENCE, HIPPO, ZIPPO, ONE, REALLY, HEAVY,...</td>\n",
       "      <td> {u'contains(DIFFERENCE)': True, u'contains(HIP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 2015</td>\n",
       "      <td>      Dave Green</td>\n",
       "      <td> 5</td>\n",
       "      <td> If I could take just one thing to a desert isl...</td>\n",
       "      <td> [COULD, TAKE, ONE, THING, DESERT, ISLAND, PROB...</td>\n",
       "      <td> {u'contains(THING)': True, u'contains(WOULDN)'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year           Author  Rank  \\\n",
       "0  2015     Darren Walsh     1   \n",
       "1  2015  Stewart Francis     2   \n",
       "2  2015        Adam Hess     3   \n",
       "3  2015     Masai Graham     4   \n",
       "4  2015       Dave Green     5   \n",
       "\n",
       "                                            Raw_joke  \\\n",
       "0  I just deleted all the German names off my pho...   \n",
       "1  Kim Kardashian is saddled with a huge arse ......   \n",
       "2              Surely every car is a people carrier?   \n",
       "3  What's the difference between a 'hippo' and a ...   \n",
       "4  If I could take just one thing to a desert isl...   \n",
       "\n",
       "                                                Joke  \\\n",
       "0        [DELETED, GERMAN, NAMES, PHONE, HANS, FREE]   \n",
       "1  [KIM, KARDASHIAN, SADDLED, HUGE, ARSE, ENOUGH,...   \n",
       "2              [SURELY, EVERY, CAR, PEOPLE, CARRIER]   \n",
       "3  [DIFFERENCE, HIPPO, ZIPPO, ONE, REALLY, HEAVY,...   \n",
       "4  [COULD, TAKE, ONE, THING, DESERT, ISLAND, PROB...   \n",
       "\n",
       "                                            Features  \n",
       "0  {u'contains(DELETED)': True, u'contains(PHONE)...  \n",
       "1  {u'contains(ENOUGH)': True, u'contains(KANYE)'...  \n",
       "2  {u'contains(EVERY)': True, u'contains(PEOPLE)'...  \n",
       "3  {u'contains(DIFFERENCE)': True, u'contains(HIP...  \n",
       "4  {u'contains(THING)': True, u'contains(WOULDN)'...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Features'] = df['Joke'].apply(lambda x:extract_features(x, get_all_words(df)))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labelling our jokes depending on what will be deemed as funny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Author</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Raw_joke</th>\n",
       "      <th>Joke</th>\n",
       "      <th>Features</th>\n",
       "      <th>Funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 2015</td>\n",
       "      <td>    Darren Walsh</td>\n",
       "      <td>  1</td>\n",
       "      <td> I just deleted all the German names off my pho...</td>\n",
       "      <td>       [DELETED, GERMAN, NAMES, PHONE, HANS, FREE]</td>\n",
       "      <td> {u'contains(DELETED)': True, u'contains(PHONE)...</td>\n",
       "      <td>  True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 2015</td>\n",
       "      <td> Stewart Francis</td>\n",
       "      <td>  2</td>\n",
       "      <td> Kim Kardashian is saddled with a huge arse ......</td>\n",
       "      <td> [KIM, KARDASHIAN, SADDLED, HUGE, ARSE, ENOUGH,...</td>\n",
       "      <td> {u'contains(ENOUGH)': True, u'contains(KANYE)'...</td>\n",
       "      <td>  True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 2015</td>\n",
       "      <td>       Adam Hess</td>\n",
       "      <td>  3</td>\n",
       "      <td>             Surely every car is a people carrier?</td>\n",
       "      <td>             [SURELY, EVERY, CAR, PEOPLE, CARRIER]</td>\n",
       "      <td> {u'contains(EVERY)': True, u'contains(PEOPLE)'...</td>\n",
       "      <td>  True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 2015</td>\n",
       "      <td>    Masai Graham</td>\n",
       "      <td>  4</td>\n",
       "      <td> What's the difference between a 'hippo' and a ...</td>\n",
       "      <td> [DIFFERENCE, HIPPO, ZIPPO, ONE, REALLY, HEAVY,...</td>\n",
       "      <td> {u'contains(DIFFERENCE)': True, u'contains(HIP...</td>\n",
       "      <td>  True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 2015</td>\n",
       "      <td>      Dave Green</td>\n",
       "      <td>  5</td>\n",
       "      <td> If I could take just one thing to a desert isl...</td>\n",
       "      <td> [COULD, TAKE, ONE, THING, DESERT, ISLAND, PROB...</td>\n",
       "      <td> {u'contains(THING)': True, u'contains(WOULDN)'...</td>\n",
       "      <td>  True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td> 2015</td>\n",
       "      <td>     Mark Nelson</td>\n",
       "      <td>  6</td>\n",
       "      <td> Jesus fed 5,000 people with two fishes and a l...</td>\n",
       "      <td> [JESUS, FED, 5, 000, PEOPLE, TWO, FISHES, LOAF...</td>\n",
       "      <td> {u'contains(5)': True, u'contains(PEOPLE)': Tr...</td>\n",
       "      <td> False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td> 2015</td>\n",
       "      <td>       Tom Parry</td>\n",
       "      <td>  7</td>\n",
       "      <td> Red sky at night. Shepherd's delight. Blue sky...</td>\n",
       "      <td> [RED, SKY, NIGHT, SHEPHERD, DELIGHT, BLUE, SKY...</td>\n",
       "      <td> {u'contains(BLUE)': True, u'contains(DAY)': Tr...</td>\n",
       "      <td> False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td> 2015</td>\n",
       "      <td>   Alun Cochrane</td>\n",
       "      <td>  8</td>\n",
       "      <td> The first time I met my wife, I knew she was a...</td>\n",
       "      <td> [FIRST, TIME, MET, WIFE, KNEW, KEEPER, WEARING...</td>\n",
       "      <td> {u'contains(KNEW)': True, u'contains(MASSIVE)'...</td>\n",
       "      <td> False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td> 2015</td>\n",
       "      <td>   Simon Munnery</td>\n",
       "      <td>  9</td>\n",
       "      <td>                   Clowns divorce. Custardy battle</td>\n",
       "      <td>               [CLOWNS, DIVORCE, CUSTARDY, BATTLE]</td>\n",
       "      <td> {u'contains(BATTLE)': True, u'contains(CUSTARD...</td>\n",
       "      <td> False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td> 2015</td>\n",
       "      <td> Grace The Child</td>\n",
       "      <td> 10</td>\n",
       "      <td> They're always telling me to live my dreams. B...</td>\n",
       "      <td> [RE, ALWAYS, TELLING, LIVE, DREAMS, WANT, NAKE...</td>\n",
       "      <td> {u'contains(DREAMS)': True, u'contains(LIVE)':...</td>\n",
       "      <td> False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year           Author  Rank  \\\n",
       "0  2015     Darren Walsh     1   \n",
       "1  2015  Stewart Francis     2   \n",
       "2  2015        Adam Hess     3   \n",
       "3  2015     Masai Graham     4   \n",
       "4  2015       Dave Green     5   \n",
       "5  2015      Mark Nelson     6   \n",
       "6  2015        Tom Parry     7   \n",
       "7  2015    Alun Cochrane     8   \n",
       "8  2015    Simon Munnery     9   \n",
       "9  2015  Grace The Child    10   \n",
       "\n",
       "                                            Raw_joke  \\\n",
       "0  I just deleted all the German names off my pho...   \n",
       "1  Kim Kardashian is saddled with a huge arse ......   \n",
       "2              Surely every car is a people carrier?   \n",
       "3  What's the difference between a 'hippo' and a ...   \n",
       "4  If I could take just one thing to a desert isl...   \n",
       "5  Jesus fed 5,000 people with two fishes and a l...   \n",
       "6  Red sky at night. Shepherd's delight. Blue sky...   \n",
       "7  The first time I met my wife, I knew she was a...   \n",
       "8                    Clowns divorce. Custardy battle   \n",
       "9  They're always telling me to live my dreams. B...   \n",
       "\n",
       "                                                Joke  \\\n",
       "0        [DELETED, GERMAN, NAMES, PHONE, HANS, FREE]   \n",
       "1  [KIM, KARDASHIAN, SADDLED, HUGE, ARSE, ENOUGH,...   \n",
       "2              [SURELY, EVERY, CAR, PEOPLE, CARRIER]   \n",
       "3  [DIFFERENCE, HIPPO, ZIPPO, ONE, REALLY, HEAVY,...   \n",
       "4  [COULD, TAKE, ONE, THING, DESERT, ISLAND, PROB...   \n",
       "5  [JESUS, FED, 5, 000, PEOPLE, TWO, FISHES, LOAF...   \n",
       "6  [RED, SKY, NIGHT, SHEPHERD, DELIGHT, BLUE, SKY...   \n",
       "7  [FIRST, TIME, MET, WIFE, KNEW, KEEPER, WEARING...   \n",
       "8                [CLOWNS, DIVORCE, CUSTARDY, BATTLE]   \n",
       "9  [RE, ALWAYS, TELLING, LIVE, DREAMS, WANT, NAKE...   \n",
       "\n",
       "                                            Features  Funny  \n",
       "0  {u'contains(DELETED)': True, u'contains(PHONE)...   True  \n",
       "1  {u'contains(ENOUGH)': True, u'contains(KANYE)'...   True  \n",
       "2  {u'contains(EVERY)': True, u'contains(PEOPLE)'...   True  \n",
       "3  {u'contains(DIFFERENCE)': True, u'contains(HIP...   True  \n",
       "4  {u'contains(THING)': True, u'contains(WOULDN)'...   True  \n",
       "5  {u'contains(5)': True, u'contains(PEOPLE)': Tr...  False  \n",
       "6  {u'contains(BLUE)': True, u'contains(DAY)': Tr...  False  \n",
       "7  {u'contains(KNEW)': True, u'contains(MASSIVE)'...  False  \n",
       "8  {u'contains(BATTLE)': True, u'contains(CUSTARD...  False  \n",
       "9  {u'contains(DREAMS)': True, u'contains(LIVE)':...  False  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "funny_threshold = 5\n",
    "df['Rank'] = df['Rank'].apply(int)\n",
    "df['Funny'] = df['Rank'] <= funny_threshold\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a labeled feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Author</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Raw_joke</th>\n",
       "      <th>Joke</th>\n",
       "      <th>Features</th>\n",
       "      <th>Funny</th>\n",
       "      <th>Labeled_Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 2015</td>\n",
       "      <td>    Darren Walsh</td>\n",
       "      <td> 1</td>\n",
       "      <td> I just deleted all the German names off my pho...</td>\n",
       "      <td>       [DELETED, GERMAN, NAMES, PHONE, HANS, FREE]</td>\n",
       "      <td> {u'contains(DELETED)': True, u'contains(PHONE)...</td>\n",
       "      <td> True</td>\n",
       "      <td> ({u'contains(DELETED)': True, u'contains(PHONE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 2015</td>\n",
       "      <td> Stewart Francis</td>\n",
       "      <td> 2</td>\n",
       "      <td> Kim Kardashian is saddled with a huge arse ......</td>\n",
       "      <td> [KIM, KARDASHIAN, SADDLED, HUGE, ARSE, ENOUGH,...</td>\n",
       "      <td> {u'contains(ENOUGH)': True, u'contains(KANYE)'...</td>\n",
       "      <td> True</td>\n",
       "      <td> ({u'contains(ENOUGH)': True, u'contains(KANYE)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 2015</td>\n",
       "      <td>       Adam Hess</td>\n",
       "      <td> 3</td>\n",
       "      <td>             Surely every car is a people carrier?</td>\n",
       "      <td>             [SURELY, EVERY, CAR, PEOPLE, CARRIER]</td>\n",
       "      <td> {u'contains(EVERY)': True, u'contains(PEOPLE)'...</td>\n",
       "      <td> True</td>\n",
       "      <td> ({u'contains(EVERY)': True, u'contains(PEOPLE)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 2015</td>\n",
       "      <td>    Masai Graham</td>\n",
       "      <td> 4</td>\n",
       "      <td> What's the difference between a 'hippo' and a ...</td>\n",
       "      <td> [DIFFERENCE, HIPPO, ZIPPO, ONE, REALLY, HEAVY,...</td>\n",
       "      <td> {u'contains(DIFFERENCE)': True, u'contains(HIP...</td>\n",
       "      <td> True</td>\n",
       "      <td> ({u'contains(DIFFERENCE)': True, u'contains(HI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 2015</td>\n",
       "      <td>      Dave Green</td>\n",
       "      <td> 5</td>\n",
       "      <td> If I could take just one thing to a desert isl...</td>\n",
       "      <td> [COULD, TAKE, ONE, THING, DESERT, ISLAND, PROB...</td>\n",
       "      <td> {u'contains(THING)': True, u'contains(WOULDN)'...</td>\n",
       "      <td> True</td>\n",
       "      <td> ({u'contains(THING)': True, u'contains(WOULDN)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year           Author  Rank  \\\n",
       "0  2015     Darren Walsh     1   \n",
       "1  2015  Stewart Francis     2   \n",
       "2  2015        Adam Hess     3   \n",
       "3  2015     Masai Graham     4   \n",
       "4  2015       Dave Green     5   \n",
       "\n",
       "                                            Raw_joke  \\\n",
       "0  I just deleted all the German names off my pho...   \n",
       "1  Kim Kardashian is saddled with a huge arse ......   \n",
       "2              Surely every car is a people carrier?   \n",
       "3  What's the difference between a 'hippo' and a ...   \n",
       "4  If I could take just one thing to a desert isl...   \n",
       "\n",
       "                                                Joke  \\\n",
       "0        [DELETED, GERMAN, NAMES, PHONE, HANS, FREE]   \n",
       "1  [KIM, KARDASHIAN, SADDLED, HUGE, ARSE, ENOUGH,...   \n",
       "2              [SURELY, EVERY, CAR, PEOPLE, CARRIER]   \n",
       "3  [DIFFERENCE, HIPPO, ZIPPO, ONE, REALLY, HEAVY,...   \n",
       "4  [COULD, TAKE, ONE, THING, DESERT, ISLAND, PROB...   \n",
       "\n",
       "                                            Features Funny  \\\n",
       "0  {u'contains(DELETED)': True, u'contains(PHONE)...  True   \n",
       "1  {u'contains(ENOUGH)': True, u'contains(KANYE)'...  True   \n",
       "2  {u'contains(EVERY)': True, u'contains(PEOPLE)'...  True   \n",
       "3  {u'contains(DIFFERENCE)': True, u'contains(HIP...  True   \n",
       "4  {u'contains(THING)': True, u'contains(WOULDN)'...  True   \n",
       "\n",
       "                                     Labeled_Feature  \n",
       "0  ({u'contains(DELETED)': True, u'contains(PHONE...  \n",
       "1  ({u'contains(ENOUGH)': True, u'contains(KANYE)...  \n",
       "2  ({u'contains(EVERY)': True, u'contains(PEOPLE)...  \n",
       "3  ({u'contains(DIFFERENCE)': True, u'contains(HI...  \n",
       "4  ({u'contains(THING)': True, u'contains(WOULDN)...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Labeled_Feature'] = zip(df['Features'],df['Funny'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(df['Labeled_Feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "           contains(GOT) = True            False : True   =      2.5 : 1.0\n",
      "          contains(WELL) = True            False : True   =      2.5 : 1.0\n",
      "           contains(SAY) = True             True : False  =      2.2 : 1.0\n",
      "           contains(ONE) = True             True : False  =      2.0 : 1.0\n",
      "          contains(MADE) = True            False : True   =      1.8 : 1.0\n",
      "          contains(DIDN) = True            False : True   =      1.8 : 1.0\n",
      "           contains(DAY) = True            False : True   =      1.8 : 1.0\n",
      "           contains(SEX) = True            False : True   =      1.8 : 1.0\n",
      "          contains(TIME) = True            False : True   =      1.8 : 1.0\n",
      "         contains(NEVER) = True            False : True   =      1.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke = 'How does NASA organize their company parties? They planet.'\n",
    "classifier.classify(extract_features(string_to_list(joke), get_all_words(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke = 'Why is 10 afraid of 7? Because 7 8 9'\n",
    "classifier.classify(extract_features(string_to_list(joke), get_all_words(df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here is the blog post:\n",
    "\n",
    "http://vknight.org/unpeudemath/code/2015/06/14/natural-language-and-predicting-funny/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke = \"some jokes are untested, in fact, I did not even write tests\"\n",
    "classifier.classify(extract_features(string_to_list(joke), get_all_words(df)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
